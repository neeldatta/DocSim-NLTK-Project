{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Accuracy of TF-IDF tool to DocSim using Abjayon Procedures\n",
    "\n",
    "#### Neel Datta\n",
    "#### August 2021\n",
    "\n",
    "This notebook looks further into the differences between TF-IDF and DocSim, this time using a malware search query and searching through four Abjayon procedure documents (actual text, not extracted from html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/neeldatta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import docsim\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tfidf import rank_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default GloVe word vector model: glove-wiki-gigaword-50\n",
      "Model loaded\n",
      "Model ready: True\n",
      "CPU times: user 21.7 s, sys: 212 ms, total: 21.9 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "docsim_obj = docsim.DocSim(verbose=True)\n",
    "# docsim_obj = docsim.DocSim_threaded(verbose=True)\n",
    "print(f'Model ready: {docsim_obj.model_ready}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in xml file of a list of URLs and converts to string list where each string is a URL\n",
    "def xmlToList(xml): \n",
    "    with open(xml, 'r') as f:\n",
    "        temp = f.read()\n",
    "    temp = re.findall(\"<loc>.*?</loc>\", temp)\n",
    "    strlist = []\n",
    "    for s in temp:\n",
    "        s = s[5:-6]\n",
    "        strlist.append(s)\n",
    "    return strlist\n",
    "    \n",
    "# Function that converts each url into a title + Data node in JSON\n",
    "def htmlToJSON(htmlIn, JSONout):\n",
    "    data = {}\n",
    "    data['data'] = []\n",
    "    for url in htmlIn:\n",
    "        while True:\n",
    "            try:\n",
    "                dpoint = [url]\n",
    "                page = urlopen(url)\n",
    "                html = page.read().decode(\"ISO-8859-1\")\n",
    "                soup = BeautifulSoup(html)\n",
    "                dpoint.append(soup.get_text())\n",
    "                data['data'].append(dpoint)\n",
    "                break\n",
    "            except HTTPError:\n",
    "                print (\"HTTPError at url: \" + url)\n",
    "                break\n",
    "    with open(JSONout, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "        \n",
    "def txtToJson(txtIn, JSONout):\n",
    "    data = {}\n",
    "    data['data'] = []\n",
    "    \n",
    "    for url in htmlIn:\n",
    "        while True:\n",
    "            try:\n",
    "                dpoint = [url]\n",
    "                page = urlopen(url)\n",
    "                html = page.read().decode(\"ISO-8859-1\")\n",
    "                soup = BeautifulSoup(html)\n",
    "                dpoint.append(soup.get_text())\n",
    "                data['data'].append(dpoint)\n",
    "                break\n",
    "            except HTTPError:\n",
    "                print (\"HTTPError at url: \" + url)\n",
    "                break\n",
    "    with open(JSONout, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    \n",
    "\n",
    "# Function that converts the list of controls/policies from a JupiterOne PDF into a list of strings\n",
    "def JSONToList(JSONin):\n",
    "    policies = pd.read_json(JSONin)\n",
    "    plist = []\n",
    "    for sec in policies['sections']:\n",
    "        for req in sec['requirements']:\n",
    "            plist.append(sec['title'] + ' ' + req['ref'] + ' : ' + req['title'] + ' : ' + req['summary'])\n",
    "    return plist\n",
    "\n",
    "\n",
    "# Function that iterates through n of the controls and compares using docsim with the JSON documents\n",
    "# and outputs file with top 5 matches for each.\n",
    "    # Takes in xml list of all URLs to compare, loads them into input urlJSON files, and outputs a CSV of each control\n",
    "    # and the 5 urls most similar to it\n",
    "    \n",
    "def finalMatches(xmlIn, urlJSON, policyJSON, CSVOut, n):\n",
    "    htmlToJSON(xmlToList(xmlIn), urlJSON)\n",
    "\n",
    "    policies = JSONToList(policyJSON)\n",
    "    \n",
    "#Currently only testing on the first 5 policies for runtime/testing purposes\n",
    "    policies = policies[:n]\n",
    "    \n",
    "# Load test data\n",
    "    with open(urlJSON) as in_file:\n",
    "        urldata = json.load(in_file)\n",
    "    titles = [item[0] for item in urldata['data']]\n",
    "    documents = [item[1] for item in urldata['data']]\n",
    "    print(f'{len(documents)} documents')\n",
    "    \n",
    "# Output findings into CSV file:\n",
    "    with open(CSVOut, mode = 'w') as csvfile:\n",
    "        data = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        data.writerow(['Policy', 'Score', 'URL'])\n",
    "        for p in policies:\n",
    "            query_string = p\n",
    "            similarities = docsim_obj.similarity_query(query_string, documents)\n",
    "            for idx, score in (sorted(enumerate(similarities), reverse=True, key=lambda x: x[1])[:5]):\n",
    "                data.writerow([query_string, str(score), titles[idx]])\n",
    "    return\n",
    "\n",
    "\n",
    "#Function that tests inputted policy string(s) against inputted list of URLs.\n",
    "def testMatchesDocSim(queries, urls, testJSON):\n",
    "    htmlToJSON(urls, testJSON)\n",
    "\n",
    "    with open(testJSON) as in_file:\n",
    "        urldata = json.load(in_file)\n",
    "    titles = [item[0] for item in urldata['data']]\n",
    "    documents = [item[1] for item in urldata['data']]\n",
    "    print(f'{len(documents)} documents')\n",
    "    \n",
    "    # Test on one string\n",
    "    query_string = queries\n",
    "    similarities = docsim_obj.similarity_query(query_string, documents)\n",
    "\n",
    "    # Output the similarity scores for top 5 documents\n",
    "    for idx, score in (sorted(enumerate(similarities), reverse=True, key=lambda x: x[1])[:5]):\n",
    "        print(f'{idx} \\t {score:0.3f} \\t {titles[idx]}')\n",
    "    return\n",
    "    \n",
    "\n",
    "def testMatchesTFIDF(queries, urls, testJSON):\n",
    "    htmlToJSON(urls, testJSON)\n",
    "\n",
    "    with open(testJSON) as in_file:\n",
    "        urldata = json.load(in_file)\n",
    "    titles = [item[0] for item in urldata['data']]\n",
    "    documents = [item[1] for item in urldata['data']]\n",
    "    print(f'{len(documents)} documents')\n",
    "    \n",
    "    # Test on one string\n",
    "    document_scores = rank_documents(queries, documents)\n",
    "\n",
    "    score_titles = [(score, title) for score, title in zip(document_scores, titles)]\n",
    "\n",
    "    for score, title in (sorted(score_titles, reverse=True, key=lambda x: x[0])[:5]):\n",
    "        print(f'{score:0.3f} \\t {title}')\n",
    "    return\n",
    "\n",
    "def testTFIDF(queries, testJSON):\n",
    "    with open(testJSON) as in_file:\n",
    "        urldata = json.load(in_file)\n",
    "    titles = [item[0] for item in urldata['data']]\n",
    "    documents = [item[1] for item in urldata['data']]\n",
    "    print(f'{len(documents)} documents')\n",
    "    \n",
    "    # Test on one string\n",
    "    document_scores = rank_documents(queries, documents)\n",
    "\n",
    "    score_titles = [(score, title) for score, title in zip(document_scores, titles)]\n",
    "\n",
    "    for score, title in (sorted(score_titles, reverse=True, key=lambda x: x[0])[:5]):\n",
    "        print(f'{score:0.3f} \\t {title}')\n",
    "    return\n",
    "\n",
    "def testDocsim(queries, testJSON):\n",
    "    with open(testJSON) as in_file:\n",
    "        urldata = json.load(in_file)\n",
    "    titles = [item[0] for item in urldata['data']]\n",
    "    documents = [item[1] for item in urldata['data']]\n",
    "    print(f'{len(documents)} documents')\n",
    "    \n",
    "    # Test on one string\n",
    "    query_string = queries\n",
    "    similarities = docsim_obj.similarity_query(query_string, documents)\n",
    "\n",
    "    # Output the similarity scores for top 5 documents\n",
    "    for idx, score in (sorted(enumerate(similarities), reverse=True, key=lambda x: x[1])[:5]):\n",
    "        print(f'{idx} \\t {score:0.3f} \\t {titles[idx]}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents\n",
      "0.042 \t Antivirus Policy\n",
      "0.028 \t Wireless Security Policy\n",
      "0.013 \t Password Policy\n",
      "0.010 \t Backup Policy\n",
      "CPU times: user 34.8 ms, sys: 2.05 ms, total: 36.9 ms\n",
      "Wall time: 36 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testTFIDF(\"Detection, prevention and recovery controls to protect against malware shall be implemented, combined with appropriate user awareness.\",\n",
    "         \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents\n",
      "4 documents loaded into corpus\n",
      "1 \t 0.468 \t Wireless Security Policy\n",
      "3 \t 0.437 \t Backup Policy\n",
      "0 \t 0.401 \t Antivirus Policy\n",
      "2 \t 0.323 \t Password Policy\n",
      "CPU times: user 18.3 s, sys: 1.52 s, total: 19.8 s\n",
      "Wall time: 5.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testDocsim(\"Detection, prevention and recovery controls to protect against malware shall be implemented, combined with appropriate user awareness.\",\n",
    "         \"test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results for TF-IDF were overall more accurate than the results when using DocSim. \n",
    "### For a query revolving around malware prevention/detection, the Antivirus policy should rank first: \n",
    "   - With TF-IDF, the test correctly assigned Antivirus policy the highest score, signifiantly greater than the other three policies. \n",
    "   - With Docsim, the test incorrectly put Wireless Security policy as the highest scoring document, with the Antivirus coming in third, and without much discrimination between the score values for the top 3 results (i.e. they all received relatively similar scoring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
